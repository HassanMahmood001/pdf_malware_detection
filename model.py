from sklearn import preprocessing
import pickle
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
import sklearn.model_selection as model_selection
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_recall_fscore_support 

dataset = pd.read_csv('Final_Dataset.csv')

X = dataset.drop('Malicious',axis=1).values
y = dataset['Malicious'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle= True)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle= True)  # 0.25 x 0.8 = 0.20



var1 = 0
maxx = 0
var2 = 0
ra = range(3,12,2)
sr = []
print("\n       --> K Neighbors Classifier <-- \n")

print(' --> Cross Validation <-- \n')
for i in ra:
    seed = 1
    scoring = 'accuracy'
    model= (KNeighborsClassifier(n_neighbors=i))

    results = []
    var = 0

    kfold = model_selection.KFold(n_splits=10, shuffle=True)
    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    if cv_results.mean() > maxx:
        maxx = cv_results.mean()
        var2 = i
    msg = "%s %i %s%f%s" % ("Validation Accuracy on n =",i, "--> ", cv_results.mean() * 100, "%")
    sr.append(cv_results.mean())
    print(msg)


c= round((maxx*100),2)
print("\n1. KNN -> Best Validation accuracy (",c,"% ) when n =", var2)

f = open("./lib/KNN_Parameters.txt", "w")
s = "Parameters --> n = " + str(var2)
f.write(s)
f.close()

knn = KNeighborsClassifier(n_neighbors=var2)
loaded_model=knn.fit(X_train, y_train)

predictor = loaded_model.predict(X_test)
cm = confusion_matrix(y_test, predictor)
print("Confusion Matrix: ")
print(cm)


fpr, tpr, thresholds = metrics.roc_curve(y_test, predictor)
print("False Positive",fpr)
print("True Positive",tpr)

auc_scoreknn = roc_auc_score(y_test, predictor)
print("Accuracy:", auc_scoreknn)

macro=precision_recall_fscore_support(y_test, predictor, average='macro')
print("Precision, Recall, 1-score (macro)",macro)
micro=precision_recall_fscore_support(y_test, predictor, average='micro')
print("Precision, Recall, 1-score (micro)",micro)
weighted=precision_recall_fscore_support(y_test, predictor, average='weighted')
print("Precision, Recall, 1-score (Weighted)",weighted)



filename = './lib/knn_finalized_model.sav'
pickle.dump(loaded_model, open(filename, 'wb'))


var1 = 0
maxx = 0
var2 = 0
ra = range(1,11)
sr = []
print("\n       --> Decision Tree Classifier <-- \n")

for i in ra:

    DT = DecisionTreeClassifier(max_depth=i)
    DT.fit(X_train, y_train)
    var1 = round((DT.score(X_train, y_train)*100),2)
    sr.append(var1)

    if var1 > maxx:
        maxx = var1
        var2 = i

    print("Training accuracy ->",round((DT.score(X_train, y_train)*100),2), "% on max_depth =",i)


print("\nBest Training accuracy (",maxx,"%) when max_depth =", var2)


seed = 1
scoring = 'accuracy'
models = []
models.append(('2. DT  ', DecisionTreeClassifier(max_depth=var2)))

print('\n --> Cross Validation <-- \n')
results = []
names = []
var = 0
for name, model in models:
    kfold = model_selection.KFold(n_splits=10, shuffle=True)
    cv_results = model_selection.cross_val_score(model, X_val, y_val, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    msg = "%s-> %s %f%s" % (name, "Validation Accuracy:", round(cv_results.mean() * 100 ,2), "%")
    print(msg)

f = open("./lib/DT_Parameters.txt", "w")
ss = "Parameters --> Max_depth = " + str(var2)
f.write(ss)
f.close()

DT = DecisionTreeClassifier(max_depth=var2)
loaded_model2=DT.fit(X_train, y_train)

filename = './lib/DT_finalized_model.sav'
pickle.dump(loaded_model2, open(filename, 'wb'))

predictor = loaded_model2.predict(X_test)
cm = confusion_matrix(y_test, predictor)
print("Confusion Matrix: ")
print(cm)

auc_scoreDT = roc_auc_score(y_test, predictor)
print("Accuracy:", auc_scoreDT)

fpr, tpr, thresholds = metrics.roc_curve(y_test, predictor)
print("False Positive",fpr)
print("True Positive",tpr)

macro=precision_recall_fscore_support(y_test, predictor, average='macro')
print("Precision, Recall, 1-score (macro)",macro)
micro=precision_recall_fscore_support(y_test, predictor, average='micro')
print("Precision, Recall, 1-score (micro)",micro)
weighted=precision_recall_fscore_support(y_test, predictor, average='weighted')
print("Precision, Recall, 1-score (Weighted)",weighted)


var1 = 0
maxx = 0
var2 = 0
var21 = 0
var33 = ['linear', 'poly']
sr = []
cc = [1 , 10]
print("\n       --> Support vector machine <-- \n")

for i in var33:
    for j in cc:

        pipe = make_pipeline(StandardScaler(), SVC(probability=False,kernel= i , C=j))
        clf = pipe.fit(X_train, y_train)
        var1 = round((clf.score(X_train, y_train)*100),2)
        sr.append(var1)

        if var1 > maxx:
            maxx = var1
            var2 = i
            var21 = j

        print("Training accuracy ->",round((clf.score(X_train, y_train)*100),2), "% on kernel =",i, "and C =",j)


var11 = 0
maaxx = 0
var22 = 0
var31 = 0
var333 = 'rbf'
srr = []
ccc = [1 , 10]
g = [0.1 , 1]

for k in ccc:
    for l in g:

        pipe = make_pipeline(StandardScaler(), SVC(kernel= 'rbf' , C=k, gamma=l))
        clf = pipe.fit(X_train, y_train)
        var11 = round((clf.score(X_train, y_train)*100),2)
        srr.append(var11)

        if var11 > maaxx:
            maaxx = var11
            var22 = k
            var31 = l

        print("Training accuracy ->",round((clf.score(X_train, y_train)*100),2), "% on kernel =",var333, ", C =",k , " & gamma =",l)    

if maxx > maaxx:
     print("\nBest Training accuracy (",maxx,"%) when kernel =", var2, ", C =",var21)
else:
     print("\nBest Training accuracy (",maaxx,"%) when kernel =", var333, ", C =",var22 , " & gamma =",var31)


seed = 1
scoring = 'accuracy'
models = []
models.append(('3. SVM  ',make_pipeline(StandardScaler(), SVC(kernel= var333, C= var22, gamma= var31))))

print('\n --> Cross Validation <-- \n')
results = []
names = []
var = 0
for name, model in models:
    kfold = model_selection.KFold(n_splits=5, shuffle=True)
    cv_results = model_selection.cross_val_score(model, X_val, y_val, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    msg = "%s-> %s %f%s" % (name, "Validation Accuracy:", round(cv_results.mean() * 100 ,2), "%")
    print(msg)


f = open("./lib/SVM_Parameters.txt", "w")
sss = "Parameters --> Kernal = " + var333 +  ", C = " + str(var22) , " & gamma = " + str(var31)
ssss = str(sss)
f.write(ssss)
f.close()

svm = make_pipeline(StandardScaler(), SVC(kernel= var333, C= var22, gamma= var31))
loaded_model3=svm.fit(X_train, y_train)

filename = './lib/SVM_model.sav'
pickle.dump(loaded_model3, open(filename, 'wb'))

predictor = loaded_model3.predict(X_test)
cm = confusion_matrix(y_test, predictor)
print("Confusion Matrix: ")
print(cm)

auc_scoreSVM = roc_auc_score(y_test, predictor)
print("Accuracy:", auc_scoreSVM)

fpr, tpr, thresholds = metrics.roc_curve(y_test, predictor)
print("False Positive",fpr)
print("True Positive",tpr)

macro=precision_recall_fscore_support(y_test, predictor, average='macro')
print("Precision, Recall, f1-score (macro)",macro)
micro=precision_recall_fscore_support(y_test, predictor, average='micro')
print("Precision, Recall, f1-score (micro)",micro)
weighted=precision_recall_fscore_support(y_test, predictor, average='weighted')
print("Precision, Recall, f1-score (Weighted)",weighted)

